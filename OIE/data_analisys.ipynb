{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-24T00:54:10.308475700Z",
     "start_time": "2023-09-24T00:54:03.281939200Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset.dataset import get_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "from final.matcher import OIE_Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "matcher = OIE_Match()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T00:54:12.406734400Z",
     "start_time": "2023-09-24T00:54:10.310595900Z"
    }
   },
   "id": "f4a85de5af59e3e7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def save_data(dataset, name: str):\n",
    "    dir = 'datasets/outputs/analisado'\n",
    "    path = pathlib.Path('datasets/outputs/analisado')\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    file_text = \"\"\n",
    "    before_tag = '\\tXX\\t-\\t-\\t-\\t-\\t-\\t*\\t'\n",
    "    for key in tqdm(dataset, desc='saving data'):\n",
    "        ext = dataset[key]['ext']['splited']\n",
    "        sent = dataset[key]['sent']['sent']\n",
    "        match = matcher.match(sent=sent, \n",
    "                              arg1=ext['arg0'], \n",
    "                              rel=ext['rel'],\n",
    "                              arg2=ext['arg1'])\n",
    "        if match[-1]:\n",
    "            for i,token in enumerate([token.text for token in nlp(sent)]):\n",
    "                if i in range(match[0][0], match[0][1]+1):\n",
    "                    if len(range(match[0][0], match[0][1]+1)) == 1:\n",
    "                        file_text += token + before_tag + \"S-ARG0\" + \"\\n\"\n",
    "                    elif i == match[0][0]:\n",
    "                        file_text += token + before_tag + \"B-ARG0\" + \"\\n\"\n",
    "                    elif i > match[0][0] and i<match[0][1]:\n",
    "                        file_text += token + before_tag + \"I-ARG0\" + \"\\n\"\n",
    "                    elif i == match[0][1]:\n",
    "                        file_text += token + before_tag + \"E-ARG0\" + \"\\n\"\n",
    "\n",
    "                elif i in range(match[1][0], match[1][1]+1):\n",
    "                    if len(range(match[1][0], match[1][1] + 1)) == 1:\n",
    "                        file_text += token + before_tag + \"S-V\" + \"\\n\"\n",
    "                    elif i == match[1][0]:\n",
    "                        file_text += token + before_tag + \"B-V\" + \"\\n\"\n",
    "                    elif i > match[1][0] and i < match[1][1]:\n",
    "                        file_text += token + before_tag + \"I-V\" + \"\\n\"\n",
    "                    elif i == match[1][1]:\n",
    "                        file_text += token + before_tag + \"E-V\" + \"\\n\"\n",
    "\n",
    "                elif i in range(match[2][0], match[2][1]+1):\n",
    "                    if len(range(match[2][0], match[2][1] + 1)) == 1:\n",
    "                        file_text += token + before_tag + \"S-ARG1\" + \"\\n\"\n",
    "                    elif i == match[2][0]:\n",
    "                        file_text += token + before_tag + \"B-ARG1\" + \"\\n\"\n",
    "                    elif i > match[2][0] and i < match[2][1]:\n",
    "                        file_text += token + before_tag + \"I-ARG1\" + \"\\n\"\n",
    "                    elif i == match[2][1]:\n",
    "                        file_text += token + before_tag + \"E-ARG1\" + \"\\n\"\n",
    "                else:\n",
    "                    file_text += token + before_tag + \"O\" + \"\\n\"\n",
    "            file_text += \"\\n\"\n",
    "    with open(dir + \"/\" + name + \".txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            txt_f = f.read()\n",
    "        except:\n",
    "            txt_f = \"\"\n",
    "        txt_f += file_text\n",
    "        f.write(txt_f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T00:54:12.406734400Z",
     "start_time": "2023-09-24T00:54:12.405407500Z"
    }
   },
   "id": "b624afc5b4760857"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_dataset(): \n",
    "    dataset = get_dataset()\n",
    "    extractions = {}\n",
    "    i = 0\n",
    "    split = 0\n",
    "    while split<=1:\n",
    "        for triple in dataset[split]:\n",
    "            sent = triple.phrase\n",
    "            sent_counter = 0\n",
    "            for token in nlp(sent):\n",
    "                sent_counter += 1\n",
    "                \n",
    "            ext = triple.gold_extractions[0]\n",
    "            merged = ext.arg0 + \" \" + ext.rel + \" \" + ext.arg1\n",
    "            ext_counter = 0\n",
    "            for token in nlp(merged):\n",
    "                ext_counter += 1\n",
    "                \n",
    "            ext = {\"length\" : ext_counter,\n",
    "                   \"merged\": merged,\n",
    "                   \"splited\" : {\n",
    "                       \"arg0\" : ext.arg0,\n",
    "                       \"rel\" : ext.rel,\n",
    "                       \"arg1\" : ext.arg1\n",
    "                        }\n",
    "                   }\n",
    "            extractions[i] = {\"sent\" : {\"sent\" : sent,\n",
    "                                        \"length\" : sent_counter\n",
    "                                        },\n",
    "                              \"ext\" : ext}\n",
    "            i+=1\n",
    "        split+=1\n",
    "    return extractions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T00:54:12.421695Z",
     "start_time": "2023-09-24T00:54:12.405407500Z"
    }
   },
   "id": "c211adf3f2a0cd5d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processando TA_train: 100%|██████████| 80411/80411 [07:19<00:00, 183.04it/s]\n",
      "processando TA_dev: 100%|██████████| 20102/20102 [01:53<00:00, 177.04it/s]\n",
      "processando TA_dev: 100%|██████████| 927/927 [00:05<00:00, 177.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T01:13:25.560466400Z",
     "start_time": "2023-09-24T00:54:12.417242200Z"
    }
   },
   "id": "3a0b98248ce982e9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdataset\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T01:13:31.113405600Z",
     "start_time": "2023-09-24T01:13:31.095641400Z"
    }
   },
   "id": "2de1c7b47dd63e77"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "same_string_extractions = {}\n",
    "minimum_extractions = {}\n",
    "small_extractions = {}\n",
    "long_extractions = {}\n",
    "small_sentences = {}\n",
    "\n",
    "long_sentences = {}\n",
    "long_sentece_small_extractions = {}\n",
    "\n",
    "for key in dataset:\n",
    "    inst = dataset[key]\n",
    "    sent_len = inst[\"sent\"][\"length\"]\n",
    "    ext_len = inst[\"ext\"][\"length\"]\n",
    "    if sent_len-1 == ext_len or sent_len == ext_len:\n",
    "        same_string_extractions[key] = inst\n",
    "    elif ext_len > 8:\n",
    "        long_extractions[key] = inst\n",
    "    elif ext_len == 3:\n",
    "        minimum_extractions[key] = inst\n",
    "    elif ext_len > 3 and ext_len <=10:\n",
    "        small_extractions[key] = inst\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T03:26:57.825853400Z",
     "start_time": "2023-09-19T03:26:57.713643600Z"
    }
   },
   "id": "54ec3545a1ab79e2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extractions with same sentence length:  16463\n",
      "extractions with one tag on arg0, one on rel and one on arg1:  927\n",
      "small extractions, token counter <= 8:  38553\n",
      "long extractions, token counter > 8:  61959\n"
     ]
    }
   ],
   "source": [
    "print(\"extractions with same sentence length: \",len(same_string_extractions))\n",
    "print(\"extractions with one tag on arg0, one on rel and one on arg1: \", len(minimum_extractions))\n",
    "print(\"small extractions, token counter <= 8: \", len(small_extractions))\n",
    "print(\"long extractions, token counter > 8: \", len(long_extractions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T03:27:41.664699500Z",
     "start_time": "2023-09-19T03:27:41.617777900Z"
    }
   },
   "id": "bd0105aa622260f8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving data: 100%|██████████| 38553/38553 [08:56<00:00, 71.83it/s]\n"
     ]
    }
   ],
   "source": [
    "save_data(small_extractions, 'small')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T03:36:41.492557900Z",
     "start_time": "2023-09-19T03:27:44.669374800Z"
    }
   },
   "id": "eff164fd22e913d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
