{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-- Local measures --#\n",
      "True Positives: {'B-ARG1': 10, 'B-ARG0': 30, 'O': 542, 'I-ARG0': 38, 'B-V': 22, 'I-ARG1': 20, 'I-V': 0}\n",
      "False Positives: {'B-ARG1': 35, 'B-ARG0': 26, 'O': 168, 'I-ARG0': 19, 'B-V': 18, 'I-ARG1': 101, 'I-V': 0}\n",
      "False Negatives: {'B-ARG1': 41, 'B-ARG0': 21, 'O': 125, 'I-ARG0': 46, 'B-V': 29, 'I-ARG1': 36, 'I-V': 69}\n",
      "\n",
      "#-- Global measures --#\n",
      "Correct predictions: 662\n",
      "Total predictions: 1029\n",
      "Accuracy: 0.6433\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "MODEL_NAME = \"LSOIE\"\n",
    "\n",
    "\n",
    "def get_dev_result(model_name: str):\n",
    "    model_path = \"..\\evaluations\\\\\" + model_name + \"_dev.txt\"\n",
    "    with open(model_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip().split(\" \") for line in lines]\n",
    "        y_true = [line[1] for line in lines if len(line) == 3]\n",
    "        y_pred = [line[2] for line in lines if len(line) == 3]\n",
    "        return y_true, y_pred\n",
    "y_true, y_pred = get_dev_result(MODEL_NAME)\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    labels = list(set(y_true))\n",
    "    df = pd.DataFrame(\n",
    "        data=confusion_matrix(y_true, y_pred, labels=labels),\n",
    "        columns=labels,\n",
    "        index=labels,\n",
    "    )\n",
    "    df.index.name = \"Y-True\"\n",
    "    df.columns.name = \"Y-Pred\"\n",
    "    return df\n",
    "\n",
    "#\n",
    "# Local (metrics per class)\n",
    "#\n",
    "df = get_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "labels = list(set(y_true))\n",
    "tps = {}\n",
    "fps = {}\n",
    "fns = {}\n",
    "for label in labels:\n",
    "    tps[label] = df.loc[label, label]\n",
    "    fps[label] = df[label].sum() - tps[label]\n",
    "    fns[label] = df.loc[label].sum() - tps[label]\n",
    "\n",
    "#\n",
    "# Global\n",
    "#\n",
    "micro_averages = {}\n",
    "macro_averages = {}\n",
    "\n",
    "correct_predictions = sum(tps.values())\n",
    "\n",
    "total_predictions = df.values.sum()\n",
    "accuracy_global = round(correct_predictions / total_predictions,4 ) if total_predictions > 0. else 0.\n",
    "\n",
    "print(\"#-- Local measures --#\")\n",
    "print(\"True Positives:\", tps)\n",
    "print(\"False Positives:\", fps)\n",
    "print(\"False Negatives:\", fns)\n",
    "\n",
    "print(\"\\n#-- Global measures --#\")\n",
    "print(\"Correct predictions:\", correct_predictions)\n",
    "print(\"Total predictions:\", total_predictions)\n",
    "print(\"Accuracy:\", accuracy_global)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-ARG0     0.5357    0.5882    0.5607        51\n",
      "      B-ARG1     0.2222    0.1961    0.2083        51\n",
      "         B-V     0.5500    0.4314    0.4835        51\n",
      "      I-ARG0     0.6667    0.4524    0.5390        84\n",
      "      I-ARG1     0.1653    0.3571    0.2260        56\n",
      "         I-V     0.0000    0.0000    0.0000        69\n",
      "           O     0.7634    0.8126    0.7872       667\n",
      "\n",
      "    accuracy                         0.6433      1029\n",
      "   macro avg     0.4148    0.4054    0.4007      1029\n",
      "weighted avg     0.6231    0.6433    0.6287      1029\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x208049039d0>",
      "text/html": "<style type=\"text/css\">\n#T_b5374_row0_col0 {\n  background-color: #aeacd2;\n  color: #000000;\n}\n#T_b5374_row0_col1 {\n  background-color: #eeecf4;\n  color: #000000;\n}\n#T_b5374_row0_col2, #T_b5374_row0_col3, #T_b5374_row0_col6, #T_b5374_row1_col2, #T_b5374_row1_col4, #T_b5374_row1_col5, #T_b5374_row1_col6, #T_b5374_row2_col6, #T_b5374_row3_col0, #T_b5374_row3_col4, #T_b5374_row3_col6, #T_b5374_row4_col0, #T_b5374_row4_col1, #T_b5374_row4_col3, #T_b5374_row4_col6, #T_b5374_row5_col4, #T_b5374_row5_col6, #T_b5374_row6_col6 {\n  background-color: #fcfbfd;\n  color: #000000;\n}\n#T_b5374_row0_col4 {\n  background-color: #f7f6fa;\n  color: #000000;\n}\n#T_b5374_row0_col5 {\n  background-color: #f1f0f6;\n  color: #000000;\n}\n#T_b5374_row1_col0, #T_b5374_row5_col0, #T_b5374_row5_col1, #T_b5374_row6_col1 {\n  background-color: #f8f6fa;\n  color: #000000;\n}\n#T_b5374_row1_col1, #T_b5374_row2_col0, #T_b5374_row2_col2, #T_b5374_row2_col4, #T_b5374_row2_col5, #T_b5374_row3_col3 {\n  background-color: #3f007d;\n  color: #f1f1f1;\n}\n#T_b5374_row1_col3, #T_b5374_row5_col2 {\n  background-color: #faf8fb;\n  color: #000000;\n}\n#T_b5374_row2_col1 {\n  background-color: #9390c3;\n  color: #f1f1f1;\n}\n#T_b5374_row2_col3 {\n  background-color: #a19eca;\n  color: #f1f1f1;\n}\n#T_b5374_row3_col1 {\n  background-color: #8885be;\n  color: #f1f1f1;\n}\n#T_b5374_row3_col2, #T_b5374_row3_col5, #T_b5374_row4_col2, #T_b5374_row4_col5, #T_b5374_row6_col2 {\n  background-color: #fbfafc;\n  color: #000000;\n}\n#T_b5374_row4_col4 {\n  background-color: #470f84;\n  color: #f1f1f1;\n}\n#T_b5374_row5_col3, #T_b5374_row6_col3 {\n  background-color: #f7f5fa;\n  color: #000000;\n}\n#T_b5374_row5_col5 {\n  background-color: #e6e5f1;\n  color: #000000;\n}\n#T_b5374_row6_col0 {\n  background-color: #9995c6;\n  color: #f1f1f1;\n}\n#T_b5374_row6_col4 {\n  background-color: #c2c3df;\n  color: #000000;\n}\n#T_b5374_row6_col5 {\n  background-color: #e2e1ef;\n  color: #000000;\n}\n</style>\n<table id=\"T_b5374\">\n  <thead>\n    <tr>\n      <th class=\"index_name level0\" >Y-Pred</th>\n      <th id=\"T_b5374_level0_col0\" class=\"col_heading level0 col0\" >B-ARG1</th>\n      <th id=\"T_b5374_level0_col1\" class=\"col_heading level0 col1\" >B-ARG0</th>\n      <th id=\"T_b5374_level0_col2\" class=\"col_heading level0 col2\" >O</th>\n      <th id=\"T_b5374_level0_col3\" class=\"col_heading level0 col3\" >I-ARG0</th>\n      <th id=\"T_b5374_level0_col4\" class=\"col_heading level0 col4\" >B-V</th>\n      <th id=\"T_b5374_level0_col5\" class=\"col_heading level0 col5\" >I-ARG1</th>\n      <th id=\"T_b5374_level0_col6\" class=\"col_heading level0 col6\" >I-V</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >Y-True</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n      <th class=\"blank col4\" >&nbsp;</th>\n      <th class=\"blank col5\" >&nbsp;</th>\n      <th class=\"blank col6\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_b5374_level0_row0\" class=\"row_heading level0 row0\" >B-ARG1</th>\n      <td id=\"T_b5374_row0_col0\" class=\"data row0 col0\" >10</td>\n      <td id=\"T_b5374_row0_col1\" class=\"data row0 col1\" >3</td>\n      <td id=\"T_b5374_row0_col2\" class=\"data row0 col2\" >30</td>\n      <td id=\"T_b5374_row0_col3\" class=\"data row0 col3\" >0</td>\n      <td id=\"T_b5374_row0_col4\" class=\"data row0 col4\" >1</td>\n      <td id=\"T_b5374_row0_col5\" class=\"data row0 col5\" >7</td>\n      <td id=\"T_b5374_row0_col6\" class=\"data row0 col6\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_b5374_level0_row1\" class=\"row_heading level0 row1\" >B-ARG0</th>\n      <td id=\"T_b5374_row1_col0\" class=\"data row1 col0\" >1</td>\n      <td id=\"T_b5374_row1_col1\" class=\"data row1 col1\" >22</td>\n      <td id=\"T_b5374_row1_col2\" class=\"data row1 col2\" >27</td>\n      <td id=\"T_b5374_row1_col3\" class=\"data row1 col3\" >1</td>\n      <td id=\"T_b5374_row1_col4\" class=\"data row1 col4\" >0</td>\n      <td id=\"T_b5374_row1_col5\" class=\"data row1 col5\" >0</td>\n      <td id=\"T_b5374_row1_col6\" class=\"data row1 col6\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_b5374_level0_row2\" class=\"row_heading level0 row2\" >O</th>\n      <td id=\"T_b5374_row2_col0\" class=\"data row2 col0\" >23</td>\n      <td id=\"T_b5374_row2_col1\" class=\"data row2 col1\" >12</td>\n      <td id=\"T_b5374_row2_col2\" class=\"data row2 col2\" >526</td>\n      <td id=\"T_b5374_row2_col3\" class=\"data row2 col3\" >18</td>\n      <td id=\"T_b5374_row2_col4\" class=\"data row2 col4\" >20</td>\n      <td id=\"T_b5374_row2_col5\" class=\"data row2 col5\" >68</td>\n      <td id=\"T_b5374_row2_col6\" class=\"data row2 col6\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_b5374_level0_row3\" class=\"row_heading level0 row3\" >I-ARG0</th>\n      <td id=\"T_b5374_row3_col0\" class=\"data row3 col0\" >0</td>\n      <td id=\"T_b5374_row3_col1\" class=\"data row3 col1\" >13</td>\n      <td id=\"T_b5374_row3_col2\" class=\"data row3 col2\" >33</td>\n      <td id=\"T_b5374_row3_col3\" class=\"data row3 col3\" >37</td>\n      <td id=\"T_b5374_row3_col4\" class=\"data row3 col4\" >0</td>\n      <td id=\"T_b5374_row3_col5\" class=\"data row3 col5\" >1</td>\n      <td id=\"T_b5374_row3_col6\" class=\"data row3 col6\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_b5374_level0_row4\" class=\"row_heading level0 row4\" >B-V</th>\n      <td id=\"T_b5374_row4_col0\" class=\"data row4 col0\" >0</td>\n      <td id=\"T_b5374_row4_col1\" class=\"data row4 col1\" >0</td>\n      <td id=\"T_b5374_row4_col2\" class=\"data row4 col2\" >31</td>\n      <td id=\"T_b5374_row4_col3\" class=\"data row4 col3\" >0</td>\n      <td id=\"T_b5374_row4_col4\" class=\"data row4 col4\" >19</td>\n      <td id=\"T_b5374_row4_col5\" class=\"data row4 col5\" >1</td>\n      <td id=\"T_b5374_row4_col6\" class=\"data row4 col6\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_b5374_level0_row5\" class=\"row_heading level0 row5\" >I-ARG1</th>\n      <td id=\"T_b5374_row5_col0\" class=\"data row5 col0\" >1</td>\n      <td id=\"T_b5374_row5_col1\" class=\"data row5 col1\" >1</td>\n      <td id=\"T_b5374_row5_col2\" class=\"data row5 col2\" >40</td>\n      <td id=\"T_b5374_row5_col3\" class=\"data row5 col3\" >2</td>\n      <td id=\"T_b5374_row5_col4\" class=\"data row5 col4\" >0</td>\n      <td id=\"T_b5374_row5_col5\" class=\"data row5 col5\" >12</td>\n      <td id=\"T_b5374_row5_col6\" class=\"data row5 col6\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_b5374_level0_row6\" class=\"row_heading level0 row6\" >I-V</th>\n      <td id=\"T_b5374_row6_col0\" class=\"data row6 col0\" >12</td>\n      <td id=\"T_b5374_row6_col1\" class=\"data row6 col1\" >1</td>\n      <td id=\"T_b5374_row6_col2\" class=\"data row6 col2\" >33</td>\n      <td id=\"T_b5374_row6_col3\" class=\"data row6 col3\" >2</td>\n      <td id=\"T_b5374_row6_col4\" class=\"data row6 col4\" >7</td>\n      <td id=\"T_b5374_row6_col5\" class=\"data row6 col5\" >14</td>\n      <td id=\"T_b5374_row6_col6\" class=\"data row6 col6\" >0</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.style.background_gradient(cmap=\"Purples\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHelsinki-NLP/opus-mt-tc-big-en-pt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m MarianTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[1;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mMarianMTModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe Olympic Games take place every four years.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(pipe(sent))\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\modeling_utils.py:2362\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2359\u001B[0m     init_contexts\u001B[38;5;241m.\u001B[39mappend(init_empty_weights())\n\u001B[0;32m   2361\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[1;32m-> 2362\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(config, \u001B[38;5;241m*\u001B[39mmodel_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[0;32m   2364\u001B[0m \u001B[38;5;66;03m# Check first if we are `from_pt`\u001B[39;00m\n\u001B[0;32m   2365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_keep_in_fp32_modules:\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:1297\u001B[0m, in \u001B[0;36mMarianMTModel.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m   1295\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, config: MarianConfig):\n\u001B[0;32m   1296\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[1;32m-> 1297\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mMarianModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1299\u001B[0m     target_vocab_size \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mvocab_size \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mshare_encoder_decoder_embeddings \u001B[38;5;28;01melse\u001B[39;00m config\u001B[38;5;241m.\u001B[39mdecoder_vocab_size\n\u001B[0;32m   1300\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_buffer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfinal_logits_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m1\u001B[39m, target_vocab_size)))\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:1115\u001B[0m, in \u001B[0;36mMarianModel.__init__\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m   1112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder \u001B[38;5;241m=\u001B[39m MarianEncoder(config, encoder_embed_tokens)\n\u001B[1;32m-> 1115\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder \u001B[38;5;241m=\u001B[39m \u001B[43mMarianDecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_embed_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[38;5;66;03m# Initialize weights and apply final processing\u001B[39;00m\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_init()\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:842\u001B[0m, in \u001B[0;36mMarianDecoder.__init__\u001B[1;34m(self, config, embed_tokens)\u001B[0m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    840\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbedding(config\u001B[38;5;241m.\u001B[39mdecoder_vocab_size, config\u001B[38;5;241m.\u001B[39md_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx)\n\u001B[1;32m--> 842\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_positions \u001B[38;5;241m=\u001B[39m \u001B[43mMarianSinusoidalPositionalEmbedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_position_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList([MarianDecoderLayer(config) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(config\u001B[38;5;241m.\u001B[39mdecoder_layers)])\n\u001B[0;32m    847\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_checkpointing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:113\u001B[0m, in \u001B[0;36mMarianSinusoidalPositionalEmbedding.__init__\u001B[1;34m(self, num_positions, embedding_dim, padding_idx)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, num_positions: \u001B[38;5;28mint\u001B[39m, embedding_dim: \u001B[38;5;28mint\u001B[39m, padding_idx: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(num_positions, embedding_dim)\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:123\u001B[0m, in \u001B[0;36mMarianSinusoidalPositionalEmbedding._init_weight\u001B[1;34m(out)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;124;03mIdentical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;124;03mthe 2nd half of the vector. [dim // 2:]\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    121\u001B[0m n_pos, dim \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    122\u001B[0m position_enc \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[1;32m--> 123\u001B[0m     [[pos \u001B[38;5;241m/\u001B[39m np\u001B[38;5;241m.\u001B[39mpower(\u001B[38;5;241m10000\u001B[39m, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m (j \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m dim) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)] \u001B[38;5;28;01mfor\u001B[39;00m pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_pos)]\n\u001B[0;32m    124\u001B[0m )\n\u001B[0;32m    125\u001B[0m out\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# set early to avoid an error in pytorch-1.8+\u001B[39;00m\n\u001B[0;32m    126\u001B[0m sentinel \u001B[38;5;241m=\u001B[39m dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m (dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:123\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;124;03mIdentical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;124;03mthe 2nd half of the vector. [dim // 2:]\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    121\u001B[0m n_pos, dim \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    122\u001B[0m position_enc \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[1;32m--> 123\u001B[0m     [[pos \u001B[38;5;241m/\u001B[39m np\u001B[38;5;241m.\u001B[39mpower(\u001B[38;5;241m10000\u001B[39m, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m (j \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m dim) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)] \u001B[38;5;28;01mfor\u001B[39;00m pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_pos)]\n\u001B[0;32m    124\u001B[0m )\n\u001B[0;32m    125\u001B[0m out\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# set early to avoid an error in pytorch-1.8+\u001B[39;00m\n\u001B[0;32m    126\u001B[0m sentinel \u001B[38;5;241m=\u001B[39m dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m (dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mE:\\poetry\\venvs\\flair-oie-_ETNQf08-py3.9\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py:123\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;124;03mIdentical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;124;03mthe 2nd half of the vector. [dim // 2:]\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    121\u001B[0m n_pos, dim \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    122\u001B[0m position_enc \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[1;32m--> 123\u001B[0m     [[\u001B[43mpos\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpower\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)] \u001B[38;5;28;01mfor\u001B[39;00m pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_pos)]\n\u001B[0;32m    124\u001B[0m )\n\u001B[0;32m    125\u001B[0m out\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# set early to avoid an error in pytorch-1.8+\u001B[39;00m\n\u001B[0;32m    126\u001B[0m sentinel \u001B[38;5;241m=\u001B[39m dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m (dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-en-pt\")\n",
    "sents = [\"The world is very big\", \"I am a student\", \"I am a teacher\", \"I live in Brazil\"]\n",
    "model_name = \"Helsinki-NLP/opus-mt-tc-big-en-pt\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "sent = \"The Olympic Games take place every four years.\"\n",
    "print(pipe(sent))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
